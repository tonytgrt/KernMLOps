{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da464b6-89fc-4ca2-9290-f3bebbe2dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!make docker-image > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62bef45-339e-44c1-8309-874c236ed23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CONTAINER_CMD=\"bash -lc 'make install-ycsb'\" make docker > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a1beeb-3882-4dd0-91c7-aa98c303c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pexpect\n",
    "import os\n",
    "import time\n",
    "\n",
    "\"\"\" Collector class has helper methods to interact with kermit\"\"\"\n",
    "class Collector: \n",
    "    def __init__(self, config: Path):\n",
    "        self.env = os.environ.copy()\n",
    "        self.env[\"INTERACTIVE\"] = \"it\"\n",
    "        self.env[\"CONTAINER_CMD\"] = f\"bash -lc 'KERNMLOPS_CONFIG_FILE={config} make collect-data'\"\n",
    "        self.collect_process : pexpect.spawn | None = None\n",
    "\n",
    "    def start_collection(self, logfile=None):\n",
    "        self.collect_process = pexpect.spawn(\"make docker\", env=self.env, timeout=None, logfile=logfile)\n",
    "        self.collect_process.expect_exact([\"Started benchmark\"])\n",
    "\n",
    "    def _after_run_generate_file_data() -> dict[str, list[Path]]:\n",
    "        start_path : Path = Path(\"./data\")\n",
    "        list_of_collect_id_dirs = start_path.glob(\"*/*/*\")\n",
    "        latest_collect_id = max(list_of_collect_id_dirs, key=os.path.getctime)\n",
    "        list_of_files = latest_collect_id.glob(\"*.*.parquet\")\n",
    "        output = {}\n",
    "        for f in list_of_files:\n",
    "            index = str(f).removeprefix(str(f.parent) + \"/\").split(\".\")[0]\n",
    "            if index not in output.keys():\n",
    "                output[index] = []\n",
    "            output[index].append(f)\n",
    "        return output\n",
    "        \n",
    "    def wait(self) -> int:\n",
    "        if self.collect_process is None:\n",
    "            return\n",
    "        self.collect_process.expect([pexpect.EOF])\n",
    "        self.collect_process.wait()\n",
    "        return Collector._after_run_generate_file_data()\n",
    "        \n",
    "    def stop_collection(self):\n",
    "        if self.collect_process is None:\n",
    "            return\n",
    "        self.collect_process.sendline(\"END\")\n",
    "        return self.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5874f9a-d168-446b-9a52-ec5b49f7c35f",
   "metadata": {},
   "source": [
    "There are two ways to run kermit:\n",
    "- With the raw config\n",
    "- With a pre-programmed benchmark config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b6f636-6e03-4a04-bc5d-6b4cff6c9988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection has started\n",
      "125494\n",
      "    PID TTY          TIME CMD\n",
      "  61723 pts/18   00:04:25 jupyter-noteboo\n",
      "  85246 pts/0    03:06:24 python\n",
      "  85328 pts/0    11:57:35 osqueryd\n",
      " 125363 pts/16   00:00:00 bash\n",
      " 125364 pts/16   00:00:00 docker\n",
      " 125440 pts/0    00:00:29 python\n",
      " 125471 pts/0    00:00:00 osqueryd\n",
      "Exit application\n",
      "{'dtlb_misses': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/dtlb_misses.end.parquet')], 'block_io': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/block_io.end.parquet')], 'file_data': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/file_data.end.parquet')], 'system_info': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/system_info.end.parquet')], 'dtlb_walk_duration': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/dtlb_walk_duration.end.parquet')], 'process_metadata': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/process_metadata.end.parquet')], 'tlb_flushes': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/tlb_flushes.end.parquet')], 'itlb_misses': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/itlb_misses.end.parquet')], 'page_fault': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/page_fault.end.parquet')], 'quanta_runtime': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/quanta_runtime.end.parquet')], 'memory_usage': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/memory_usage.end.parquet')], 'process_trace': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/process_trace.end.parquet')], 'quanta_queued_time': [PosixPath('data/curated/faux/d5fc6696-3d6a-41ab-8123-9df36aef36b8/quanta_queued_time.end.parquet')]}\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "collect = Collector(\"./config/raw_overrides.yaml\")\n",
    "# This creates a raw collector, I suggest looking into this file to learn more\n",
    "\n",
    "w = open(\"hello.txt\", \"bw\")\n",
    "collect.start_collection(logfile=w)\n",
    "print(\"Collection has started\")\n",
    "# Start collection\n",
    "\n",
    "f = open(\"blah.txt\", \"w\")\n",
    "bench_test = subprocess.Popen([\"cat\", \"defaults.yaml\"], stdout=f)\n",
    "bench_test.wait()\n",
    "# Run benchmark application\n",
    "\n",
    "# Run a program that causes page faults\n",
    "!python -c \"import numpy as np; a = np.zeros((1000, 1000, 100))\" & echo $!\n",
    "!ps -a\n",
    "\n",
    "print(\"Exit application\")\n",
    "raw_coll_info = collect.stop_collection()\n",
    "print(raw_coll_info)\n",
    "# Stop the Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68efc94-d113-4ea6-afd5-098f2f509ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 11)\n",
      "┌─────┬────────┬────────┬──────────────┬───┬──────────┬─────────┬─────────┬────────────────────────┐\n",
      "│ cpu ┆ pid    ┆ tgid   ┆ ts_uptime_us ┆ … ┆ is_write ┆ is_exec ┆ comm    ┆ collection_id          │\n",
      "│ --- ┆ ---    ┆ ---    ┆ ---          ┆   ┆ ---      ┆ ---     ┆ ---     ┆ ---                    │\n",
      "│ i64 ┆ i64    ┆ i64    ┆ i64          ┆   ┆ bool     ┆ bool    ┆ str     ┆ str                    │\n",
      "╞═════╪════════╪════════╪══════════════╪═══╪══════════╪═════════╪═════════╪════════════════════════╡\n",
      "│ 0   ┆ 125057 ┆ 125053 ┆ 238548542606 ┆ … ┆ true     ┆ false   ┆ python3 ┆ d5fc6696-3d6a-41ab-812 │\n",
      "│     ┆        ┆        ┆              ┆   ┆          ┆         ┆         ┆ 3-9df36a…              │\n",
      "│ 0   ┆ 125057 ┆ 125053 ┆ 238548542666 ┆ … ┆ true     ┆ false   ┆ python3 ┆ d5fc6696-3d6a-41ab-812 │\n",
      "│     ┆        ┆        ┆              ┆   ┆          ┆         ┆         ┆ 3-9df36a…              │\n",
      "│ 0   ┆ 125057 ┆ 125053 ┆ 238548542684 ┆ … ┆ true     ┆ false   ┆ python3 ┆ d5fc6696-3d6a-41ab-812 │\n",
      "│     ┆        ┆        ┆              ┆   ┆          ┆         ┆         ┆ 3-9df36a…              │\n",
      "│ 0   ┆ 125057 ┆ 125053 ┆ 238548542697 ┆ … ┆ true     ┆ false   ┆ python3 ┆ d5fc6696-3d6a-41ab-812 │\n",
      "│     ┆        ┆        ┆              ┆   ┆          ┆         ┆         ┆ 3-9df36a…              │\n",
      "│ 0   ┆ 125057 ┆ 125053 ┆ 238548542708 ┆ … ┆ true     ┆ false   ┆ python3 ┆ d5fc6696-3d6a-41ab-812 │\n",
      "│     ┆        ┆        ┆              ┆   ┆          ┆         ┆         ┆ 3-9df36a…              │\n",
      "└─────┴────────┴────────┴──────────────┴───┴──────────┴─────────┴─────────┴────────────────────────┘\n",
      "Total faults: 16032\n",
      "Major faults: 21\n"
     ]
    }
   ],
   "source": [
    "# Analyze page fault results here\n",
    "import polars as pl\n",
    "df = pl.read_parquet(raw_coll_info[\"page_fault\"])\n",
    "print(df.head())\n",
    "print(f\"Total faults: {len(df)}\")\n",
    "print(f\"Major faults: {df.filter(pl.col('is_major')).height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c72431-e9f9-401e-a3a6-1e69dd1063f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125806\n"
     ]
    }
   ],
   "source": [
    "# New Page Fault Collector\n",
    "collect = Collector(\"./config/raw_overrides.yaml\")\n",
    "log = open(\"page_fault_log.txt\", \"bw\")\n",
    "    \n",
    "collect.start_collection(logfile=log)\n",
    "\n",
    "# Run a program that causes page faults\n",
    "# !python -c \"import numpy as np; a = np.zeros((1000, 1000, 100))\" & echo $!\n",
    "#!python -c \"import numpy as np; a = np.zeros((100, 100, 10))\" & echo $!\n",
    "#!python -c \"import numpy as np; a = np.zeros((1, 1, 1))\" & echo $!\n",
    "\n",
    "# Exactly 1 major fault\n",
    "!python -c \"import os; open('/tmp/x','wb').write(b'X'*4096); mem = bytearray(int(open('/proc/meminfo').read().split('MemAvailable:')[1].split()[0])*900); os.system('echo 1 | sudo tee /proc/sys/vm/drop_caches >/dev/null'); data = open('/tmp/x','rb').read()\" & echo $!\n",
    "\n",
    "data = collect.stop_collection()\n",
    "log.close()\n",
    "\n",
    "# Check what was collected\n",
    "print(\"Available keys:\", data.keys())\n",
    "print(data)\n",
    "\n",
    "# Read the log to see if there were errors\n",
    "# with open(\"page_fault_log.txt\", \"r\") as f:\n",
    "#    print(\"Log contents:\", f.read())\n",
    "\n",
    "# Analyze results\n",
    "import polars as pl\n",
    "df = pl.read_parquet(data[\"page_fault\"])\n",
    "print(df.head())\n",
    "print(f\"Total faults: {len(df)}\")\n",
    "print(f\"Major faults: {df.filter(pl.col('is_major')).height}\")\n",
    "# Check fault patterns\n",
    "summary = df.group_by([\"pid\", \"comm\", \"is_major\"]).len().sort(\"is_major\", descending=True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b719918-a008-4385-8c0b-59fd99faa7c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This is a simple redis benchmark config\u001b[39;00m\n\u001b[32m      4\u001b[39m w = \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mhello.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbw\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mcollect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Start collection\u001b[39;00m\n\u001b[32m      8\u001b[39m start_coll_info = collect.wait()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mCollector.start_collection\u001b[39m\u001b[34m(self, logfile)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart_collection\u001b[39m(\u001b[38;5;28mself\u001b[39m, logfile=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mself\u001b[39m.collect_process = pexpect.spawn(\u001b[33m\"\u001b[39m\u001b[33mmake docker\u001b[39m\u001b[33m\"\u001b[39m, env=\u001b[38;5;28mself\u001b[39m.env, timeout=\u001b[38;5;28;01mNone\u001b[39;00m, logfile=logfile)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect_process\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpect_exact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mStarted benchmark\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kernmlops/.venv/lib/python3.12/site-packages/pexpect/spawnbase.py:432\u001b[39m, in \u001b[36mSpawnBase.expect_exact\u001b[39m\u001b[34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[39m\n\u001b[32m    430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m expect_async(exp, timeout)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kernmlops/.venv/lib/python3.12/site-packages/pexpect/expect.py:169\u001b[39m, in \u001b[36mExpecter.expect_loop\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.timeout()\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m incoming = \u001b[43mspawn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.spawn.delayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    171\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m.spawn.delayafterread)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kernmlops/.venv/lib/python3.12/site-packages/pexpect/pty_spawn.py:500\u001b[39m, in \u001b[36mspawn.read_nonblocking\u001b[39m\u001b[34m(self, size, timeout)\u001b[39m\n\u001b[32m    495\u001b[39m         timeout = \u001b[32m2\u001b[39m\n\u001b[32m    497\u001b[39m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (timeout != \u001b[32m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m).read_nonblocking(size)\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.isalive():\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# Some platforms, such as Irix, will claim that their\u001b[39;00m\n\u001b[32m    505\u001b[39m     \u001b[38;5;66;03m# processes are alive; timeout on the select; and\u001b[39;00m\n\u001b[32m    506\u001b[39m     \u001b[38;5;66;03m# then finally admit that they are not alive.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kernmlops/.venv/lib/python3.12/site-packages/pexpect/pty_spawn.py:450\u001b[39m, in \u001b[36mspawn.read_nonblocking.<locals>.select\u001b[39m\u001b[34m(timeout)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect\u001b[39m(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kernmlops/.venv/lib/python3.12/site-packages/pexpect/utils.py:143\u001b[39m, in \u001b[36mselect_ignore_interrupts\u001b[39m\u001b[34m(iwtd, owtd, ewtd, timeout)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    145\u001b[39m         err = sys.exc_info()[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "collect = Collector(\"./config/start_overrides.yaml\")\n",
    "# This is a simple redis benchmark config\n",
    "\n",
    "w = open(\"hello.txt\", \"bw\")\n",
    "collect.start_collection(logfile=w)\n",
    "# Start collection\n",
    "\n",
    "start_coll_info = collect.wait()\n",
    "#Wait for collector to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77c577-d4bd-4c97-86dd-f69388c796de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_coll_info.keys())\n",
    "print(start_coll_info.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb351660-009f-4c1f-9cd6-8d385159c023",
   "metadata": {},
   "source": [
    "Now let's try to examine some of the system information from this.\n",
    "I use polars, you can use whatever you like as far as data frames go, so long as they can read parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f164d85-48c6-4a1e-992c-28c17ac35fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_parquet(raw_coll_info[\"process_trace\"])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9258bc08-a748-4cb4-9ad8-466aeec46b6b",
   "metadata": {},
   "source": [
    "As a very easy excercise we could filter out the processes that are created during the life of the program and give them the name of the last exec call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b0c2e-8e9f-4422-b729-be8c0a2ae1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_parquet(raw_coll_info[\"process_trace\"])\n",
    "\n",
    "def filter_process_trace(process_trace_df: pl.DataFrame) -> pl.DataFrame :\n",
    "    df = process_trace_df\n",
    "    # Filter just the processes\n",
    "    df = df.filter(pl.col(\"tgid\") == pl.col(\"pid\")).drop(\"collection_id\")\n",
    "\n",
    "    # Find the last name of each process\n",
    "    start_df = df.sort(pl.col(\"ts_ns\"), descending = True)\n",
    "    helper_dict = {}\n",
    "    for row in start_df.iter_rows():\n",
    "        pid = row[0]\n",
    "        comm = row[3]\n",
    "        if pid in helper_dict.keys() or comm == \"\": \n",
    "            continue\n",
    "        helper_dict[pid] = comm\n",
    "\n",
    "    # Separate the start and end\n",
    "    full_df = start_df.with_columns(pl.col(\"pid\").map_elements(lambda x : helper_dict.get(x, \"\"), return_dtype=str).alias(\"full_name\"))\n",
    "    full_df = full_df.drop([\"tgid\", \"name\"])\n",
    "    start_df = full_df.filter(pl.col(\"cap_type\") == \"start\").rename({\"ts_ns\": \"start_ns\"}).drop(\"cap_type\")\n",
    "    end_df = full_df.filter(pl.col(\"cap_type\") == \"end\").rename({\"ts_ns\": \"end_ns\"}).drop([\"cap_type\", \"full_name\"])\n",
    "\n",
    "    # Join them to get the process table\n",
    "    return start_df.join(end_df, \"pid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0247cd05-d451-48b0-a83f-a2404f9f5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_process_trace(pl.read_parquet(raw_coll_info[\"process_trace\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705e626-63c6-42da-9d6e-4a9f916e8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_process_trace(pl.read_parquet(start_coll_info[\"process_trace\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fa599-56a0-4773-be03-7629f6d337a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "def filter_process_trace(process_trace_df: pl.DataFrame) -> pl.DataFrame :\n",
    "    df = process_trace_df\n",
    "    # Filter just the processes\n",
    "    df = df.filter(pl.col(\"tgid\") == pl.col(\"pid\")).drop(\"collection_id\")\n",
    "\n",
    "    # Find the last name of each process\n",
    "    start_df = df.sort(pl.col(\"ts_ns\"), descending = True)\n",
    "    helper_dict = {}\n",
    "    for row in start_df.iter_rows():\n",
    "        pid = row[0]\n",
    "        comm = row[3]\n",
    "        if pid in helper_dict.keys() or comm == \"\": \n",
    "            continue\n",
    "        helper_dict[pid] = comm\n",
    "\n",
    "    # Separate the start and end\n",
    "    full_df = start_df.with_columns(pl.col(\"pid\").map_elements(lambda x : helper_dict.get(x, \"\"), return_dtype=str).alias(\"full_name\"))\n",
    "    full_df = full_df.drop([\"tgid\", \"name\"])\n",
    "    start_df = full_df.filter(pl.col(\"cap_type\") == \"start\").rename({\"ts_ns\": \"start_ns\"}).drop(\"cap_type\")\n",
    "    end_df = full_df.filter(pl.col(\"cap_type\") == \"end\").rename({\"ts_ns\": \"end_ns\"}).drop([\"cap_type\", \"full_name\"])\n",
    "\n",
    "    # Join them to get the process table\n",
    "    combined_df = start_df.join(end_df, \"pid\")\n",
    "    return combined_df.with_columns((pl.col(\"end_ns\") - pl.col(\"start_ns\")).alias(\"duration\"))\n",
    "\n",
    "def process_trace_start_end_ts(process_trace_df: pl.DataFrame, proc_name: str, index: int) ->(int, int, int):\n",
    "    trace_df = filter_process_trace(process_trace_df).sort(pl.col(\"start_ns\"))\n",
    "    df = trace_df.filter(pl.col(\"full_name\") == proc_name)\n",
    "    print(df)\n",
    "    df = df[index]\n",
    "    pid = df[\"pid\"][0]\n",
    "    start_ns = df[\"start_ns\"][0]\n",
    "    end_ns = df[\"end_ns\"][0]\n",
    "    return pid, start_ns, end_ns\n",
    "\n",
    "def clean_rss_pid(rss_df: pl.DataFrame, pid: int) -> pl.DataFrame:\n",
    "    df = rss_df.drop([\"pid\", \"collection_id\"]).sort(pl.col(\"ts_ns\"))\n",
    "    df = df.filter(pl.col(\"tgid\") == pid)\n",
    "    df = df.with_columns(pl.when(pl.col(\"member\") == \"MM_FILEPAGES\")\n",
    "                     .then(pl.col(\"count\"))\n",
    "                     .otherwise(None)\n",
    "                     .fill_null(strategy=\"forward\")\n",
    "                     .fill_null(strategy=\"backward\")\n",
    "                     .alias(\"file\"))\n",
    "    df = df.with_columns(pl.when(pl.col(\"member\") == \"MM_ANONPAGES\")\n",
    "                     .then(pl.col(\"count\"))\n",
    "                     .otherwise(None)\n",
    "                     .fill_null(strategy=\"forward\")\n",
    "                     .fill_null(strategy=\"backward\")\n",
    "                     .alias(\"anon\"))\n",
    "    df = df.with_columns(pl.when(pl.col(\"member\") == \"MM_SWAPENTS\")\n",
    "                     .then(pl.col(\"count\"))\n",
    "                     .otherwise(None)\n",
    "                     .fill_null(strategy=\"forward\")\n",
    "                     .fill_null(strategy=\"backward\")\n",
    "                     .alias(\"swap\"))\n",
    "    df = df.drop([\"member\", \"count\"])\n",
    "    zero_df = pl.DataFrame({\"tgid\": pid, \"ts_ns\" : -1, \"file\" : 0, \"anon\": 0, \"swap\": 0})\n",
    "    df = pl.concat([df, zero_df]).sort(\"ts_ns\")\n",
    "    df = df.fill_null(strategy=\"forward\")\n",
    "    df = df.filter(pl.col(\"ts_ns\") >= 0)\n",
    "    df = df.with_columns((pl.col(\"file\") + pl.col(\"anon\") + pl.col(\"swap\")).alias(\"count\"))\n",
    "    df = df.drop([\"file\", \"anon\", \"swap\"])\n",
    "    return df\n",
    "\n",
    "def filter_rss_with_ts(rss_trace_df: pl.DataFrame, start: int, end: int):\n",
    "    print(start, end)\n",
    "    new_frame_dict = {}\n",
    "    for column_name in rss_trace_df.columns:\n",
    "        new_frame_dict[column_name] = [None, None]\n",
    "    new_frame_dict[\"ts_ns\"] = [start, end]\n",
    "    df = rss_trace_df.vstack(pl.DataFrame(new_frame_dict))\n",
    "    df = df.sort(pl.col(\"ts_ns\")).fill_null(strategy=\"forward\").fill_null(strategy=\"backward\")\n",
    "    return df.filter(pl.col(\"ts_ns\").is_between(start, end, closed='both'))\n",
    "\n",
    "def get_proper_rss(proc_path: Path, rss_path: Path, rss_name: str, rss_ind: int, runner_name: str, runner_ind: int, tag:str):\n",
    "    proc_trace_df = pl.read_parquet(proc_path)\n",
    "    rss_df = pl.read_parquet(rss_path)\n",
    "\n",
    "    _, start, end = process_trace_start_end_ts(proc_trace_df, runner_name, runner_ind)\n",
    "    pid, _, _ = process_trace_start_end_ts(proc_trace_df, rss_name, rss_ind)\n",
    "    clean_rss_df = filter_rss_with_ts(clean_rss_pid(rss_df, pid), start, end)\n",
    "    return clean_rss_df.with_columns((pl.col(\"ts_ns\") - pl.min(\"ts_ns\")).alias(\"norm_ts_ns\")).with_columns(pl.lit(tag).alias('policy'))\n",
    "\n",
    "from pathlib import Path\n",
    "from plotnine import ggplot, aes, geom_line, geom_point, labs\n",
    "\n",
    "def create_graph(inputs: [(str, dict[str, Path])], proc_tag: str, proc_ind: int, time_proc_tag: str, time_proc_index: int, title: str) -> None:\n",
    "    df = pl.DataFrame()\n",
    "    for (tag, filedict) in inputs:\n",
    "        append_df = get_proper_rss(filedict[\"process_trace\"],\n",
    "                                   filedict[\"mm_rss_stat\"],\n",
    "                                   proc_tag, proc_ind,\n",
    "                                   time_proc_tag,\n",
    "                                   time_proc_index,\n",
    "                                   tag).drop([\"tgid\", \"ts_ns\"])\n",
    "        df = pl.concat([df, append_df])\n",
    "    df = df.with_columns((pl.col(\"norm_ts_ns\") / (10**9)/ 60).alias(\"norm_ts_mins\"))\n",
    "    plt0 = (ggplot(df)\n",
    "            + aes(\"norm_ts_mins\", y=\"count\", colour=\"policy\")\n",
    "            + geom_point()\n",
    "            + geom_line()\n",
    "            + labs(x=\"Time (mins)\",\n",
    "                   y=\"4kB Pages\",\n",
    "                   title=title)\n",
    "           )\n",
    "    return plt0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94874478-33b2-4c67-989c-dc98cfc529f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect = Collector(\"./config/redis_never.yaml\")\n",
    "collect.start_collection(None)\n",
    "redis_never_info = collect.wait()\n",
    "collect = Collector(\"./config/redis_madvise.yaml\")\n",
    "collect.start_collection(None)\n",
    "redis_madvise_info = collect.wait()\n",
    "collect = Collector(\"./config/redis_always.yaml\")\n",
    "collect.start_collection(None)\n",
    "redis_always_info = collect.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcfd78-4c61-4c00-b3a2-5fb4d8a415cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "plt = create_graph([(\"4k\", redis_never_info),\n",
    "                    (\"madvise\", redis_madvise_info),\n",
    "                    (\"thp\", redis_always_info)],\n",
    "                   \"redis-server\", 0, \n",
    "                   \"redis-server\", 0,\n",
    "                   \"Redis driven by YCSB with Insertions and Deletes using Jemalloc\")\n",
    "plt.save(\"deletes-redis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28cd4d-c553-467e-83e3-85cf2a64bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"./deletes-redis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad914c-bd29-4e80-a5c9-f37cb88f14d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
